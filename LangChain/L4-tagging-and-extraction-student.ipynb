{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16de7336",
   "metadata": {},
   "source": [
    "# Tagging and Extraction Using OpenAI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb41f5f4-df8d-4d04-9eaa-193b8c29b00b",
   "metadata": {
    "height": 116,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bfb2ede9-b0b4-4c8c-b00f-9a9911f38614",
   "metadata": {
    "height": 78
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b3ae5481-4155-4831-a5dd-4c183b3b4990",
   "metadata": {
    "height": 95
   },
   "outputs": [],
   "source": [
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n",
    "    language: str = Field(description=\"language of text (should be in full text. Ex: English, Vietnamese, etc.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3cd656b2-62be-49d4-a277-b920c67203c1",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Tagging',\n",
       " 'description': 'Tag the piece of text with particular info.',\n",
       " 'parameters': {'properties': {'sentiment': {'description': 'sentiment of text, should be `pos`, `neg`, or `neutral`',\n",
       "    'type': 'string'},\n",
       "   'language': {'description': 'language of text (should be in full text. Ex: English, Vietnamese, etc.)',\n",
       "    'type': 'string'}},\n",
       "  'required': ['sentiment', 'language'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_openai_function(Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed8b15a7-450c-43d6-af44-ca63800a4619",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2cc5bac3-3783-4ce7-9de6-83c905fba7c5",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "model = ChatGroq(model_name=\"llama3-groq-70b-8192-tool-use-preview\", temperature=0)\n",
    "# model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "798ac5b3-7e47-4cfb-8173-63900cf1e7f6",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "tagging_functions = [convert_to_openai_function(Tagging)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d558031-18cf-4791-b061-8911ce314605",
   "metadata": {
    "height": 82
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "00607aff-a64e-42b7-8cf4-893e8393dd33",
   "metadata": {
    "height": 82
   },
   "outputs": [],
   "source": [
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"Tagging\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1d0bc519-2b8e-40d0-88ec-fc5ef0291f16",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8688fdba-0996-446c-a77b-318094944998",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"language\": \"English\", \"sentiment\": \"pos\"}', 'name': 'Tagging'}}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 286, 'total_tokens': 304, 'completion_time': 0.054920107, 'prompt_time': 0.021580864, 'queue_time': 0.012295988999999997, 'total_time': 0.076500971}, 'model_name': 'llama3-groq-70b-8192-tool-use-preview', 'system_fingerprint': 'fp_ee4b521143', 'finish_reason': 'function_call', 'logprobs': None}, id='run-fbad4417-76d6-454f-b7de-a950cc52811f-0', usage_metadata={'input_tokens': 286, 'output_tokens': 18, 'total_tokens': 304})"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"I love langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7df9aac5-7194-4a12-bda7-e7e83e705929",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"language\": \"Italian\", \"sentiment\": \"neg\"}', 'name': 'Tagging'}}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 289, 'total_tokens': 307, 'completion_time': 0.055076577, 'prompt_time': 0.021939113, 'queue_time': 0.011883937, 'total_time': 0.07701569}, 'model_name': 'llama3-groq-70b-8192-tool-use-preview', 'system_fingerprint': 'fp_ee4b521143', 'finish_reason': 'function_call', 'logprobs': None}, id='run-4c0e37b4-2b6e-4d6c-a1c8-59f61b58f708-0', usage_metadata={'input_tokens': 289, 'output_tokens': 18, 'total_tokens': 307})"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0749e408-3878-4ddd-ad33-8d5b8418a3f2",
   "metadata": {
    "height": 44
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dc45243e-7225-427d-b679-d737ebaec780",
   "metadata": {
    "height": 44
   },
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7ba84e64-518c-40e1-a7c9-d174314bc3fb",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'language': 'Italian', 'sentiment': 'neg'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e417b4-9306-413f-865f-e13dbd2d0196",
   "metadata": {},
   "source": [
    "# Extraction\n",
    "\n",
    "Extraction is similar to tagging, but used for extracting multiple pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97338dce-a61a-4f8b-912c-6108dcb86183",
   "metadata": {
    "height": 99
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f558fb45-f3a5-47be-8778-dddec2d00ba1",
   "metadata": {
    "height": 65
   },
   "outputs": [],
   "source": [
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eeb6028-0ade-46f6-a899-ca10f185bb24",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Information',\n",
       " 'description': 'Information to extract.',\n",
       " 'parameters': {'properties': {'people': {'description': 'List of info about people',\n",
       "    'items': {'description': 'Information about a person.',\n",
       "     'properties': {'name': {'description': \"person's name\", 'type': 'string'},\n",
       "      'age': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "       'description': \"person's age\"}},\n",
       "     'required': ['name', 'age'],\n",
       "     'type': 'object'},\n",
       "    'type': 'array'}},\n",
       "  'required': ['people'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_openai_function(Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f16ce50e-bad7-4fbb-b9e2-0adae6fc55f2",
   "metadata": {
    "height": 61
   },
   "outputs": [],
   "source": [
    "extraction_functions = [convert_to_openai_function(Information)]\n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "3ed58069-3f7c-433e-93ed-5660d21435c9",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"people\": [{\"name\": \"Joe\", \"age\": 30}, {\"name\": \"Martha\", \"age\": null}]}', 'name': 'Information'}}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 332, 'total_tokens': 365, 'completion_time': 0.103545872, 'prompt_time': 0.02424242, 'queue_time': 0.008692686999999998, 'total_time': 0.127788292}, 'model_name': 'llama3-groq-70b-8192-tool-use-preview', 'system_fingerprint': 'fp_ee4b521143', 'finish_reason': 'function_call', 'logprobs': None}, id='run-bf32d4e0-2fdf-4f6c-9746-49b52ea6fe5d-0', usage_metadata={'input_tokens': 332, 'output_tokens': 33, 'total_tokens': 365})"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_model.invoke(\"Joe is 30, his mom is Martha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "172df097-250a-4813-b76d-21436c13056d",
   "metadata": {
    "height": 95
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfec48d7-25a2-46d7-a7a2-33284b577dd3",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f19622af-4b01-4145-ae5a-af15b551a182",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"people\": [{\"name\": \"Joe\", \"age\": 30}, {\"name\": \"Martha\", \"age\": null}]}', 'name': 'Information'}}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 348, 'total_tokens': 381, 'completion_time': 0.106709245, 'prompt_time': 0.041347017, 'queue_time': 0.0012432009999999993, 'total_time': 0.148056262}, 'model_name': 'llama3-groq-70b-8192-tool-use-preview', 'system_fingerprint': 'fp_ee4b521143', 'finish_reason': 'function_call', 'logprobs': None}, id='run-81f33595-b577-416b-8b90-0e30051ab34e-0', usage_metadata={'input_tokens': 348, 'output_tokens': 33, 'total_tokens': 381})"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "38989431-9a61-461e-a86f-61a7dddab63c",
   "metadata": {
    "height": 44
   },
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "13ac89c9-1e8d-4e11-8bca-909a6c34d23c",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Joe', 'age': 30}, {'name': 'Martha', 'age': None}]}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8db4b39-c28b-4c0e-8b9a-55ceb8ba817e",
   "metadata": {
    "height": 44
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2901d3ac-4dfc-4fb9-afd3-ab056489d3ae",
   "metadata": {
    "height": 44
   },
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c7eff400-9f3a-42a8-ba4a-a3757e7939e2",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Joe', 'age': 30}, {'name': 'Martha', 'age': None}]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8524f3-a663-4007-ad59-52dfe00343e9",
   "metadata": {},
   "source": [
    "# Doing it for real\n",
    "\n",
    "We can apply tagging to a larger body of text.\n",
    "\n",
    "For example, let's load this blog post and extract tag information from a sub-set of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc7c4a8c-d4c8-4400-b1d3-5c7c0c25786e",
   "metadata": {
    "height": 78
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.promptingguide.ai/techniques/cot\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dbd2e910-e0e0-447a-8118-6fe792f04e15",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "doc = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b5e39f78-ff18-4016-a751-7d0e4c82bb36",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "page_content = doc.page_content[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb8d98ee-e9b2-4ce8-982a-c06dc006da76",
   "metadata": {
    "height": 31,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-Thought Prompting | Prompt Engineering Guide Prompt Engineering Guide🎓 Prompt Engineering Course🎓 Prompt Engineering CourseServicesServicesAboutAboutGitHubGitHub (opens in a new tab)DiscordDiscord (opens in a new tab)Prompt EngineeringIntroductionLLM SettingsBasics of PromptingPrompt ElementsGeneral Tips for Designing PromptsExamples of PromptsTechniquesZero-shot PromptingFew-shot PromptingChain-of-Thought PromptingMeta PromptingSelf-ConsistencyGenerate Knowledge PromptingPrompt ChainingTree of ThoughtsRetrieval Augmented GenerationAutomatic Reasoning and Tool-useAutomatic Prompt EngineerActive-PromptDirectional Stimulus PromptingProgram-Aided Language ModelsReActReflexionMultimodal CoTGraph PromptingGuidesOptimizing PromptsApplicationsFine-tuning GPT-4oFunction CallingContext Caching with LLMsGenerating DataGenerating Synthetic Dataset for RAGTackling Generated Datasets DiversityGenerating CodeGraduate Job Classification Case StudyPrompt FunctionPrompt HubClassificationSentim\n"
     ]
    }
   ],
   "source": [
    "print(page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9db0d107-5284-4253-b769-dfedb97ce95d",
   "metadata": {
    "height": 112
   },
   "outputs": [],
   "source": [
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a concise summary of the content.\")\n",
    "    language: str = Field(description=\"Provide the language that the content is written in.\")\n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6bfe7fe6-a86d-416c-a7f2-373dc70fcba5",
   "metadata": {
    "height": 150
   },
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "# model = ChatGroq(model_name=\"llama3-groq-70b-8192-tool-use-preview\", temperature=0)\n",
    "overview_tagging_function = [\n",
    "    convert_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}\n",
    ")\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e932e6a",
   "metadata": {},
   "source": [
    "open ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "518f2337-a8eb-4eff-b764-b70e48545d19",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'The article discusses various techniques in prompt engineering, particularly focusing on Chain-of-Thought (CoT) prompting and its applications in reasoning tasks. It highlights the introduction of CoT prompting by Wei et al. (2022) and the concept of zero-shot CoT prompting by Kojima et al. (2022). Additionally, it mentions the work of Zhang et al. (2022) on Automatic Chain-of-Thought (Auto-CoT) prompting, which aims to automate the generation of reasoning chains for demonstrations.',\n",
       " 'language': 'English',\n",
       " 'keywords': 'Chain-of-Thought prompting, zero-shot CoT, Automatic Chain-of-Thought, Wei et al. (2022), Kojima et al. (2022), Zhang et al. (2022)'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17dbc7f",
   "metadata": {},
   "source": [
    "llama 70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2567b33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keywords': 'Chain-of-Thought Prompting, Zero-shot COT Prompting, Automatic Chain-of-Thought, Auto-CoT, question clustering, demonstration sampling, reasoning chain, rationale, heuristics, language model, LLM, GPT-4, Wei et al. 2022, Zhang et al. 2022, DAIR.AI Academy, PROMPTING20, discount, students, suboptimal solutions, manual efforts, LLMs, reasoning chains, demonstrations, diversity, mistakes, clusters, representative question, heuristics, tokens, reasoning steps, rationale, simple, accurate, process, code, available, here',\n",
       " 'language': 'English',\n",
       " 'summary': 'This article discusses various techniques in prompt engineering, including Chain-of-Thought (CoT) Prompting, Zero-shot COT Prompting, and Automatic Chain-of-Thought (Auto-CoT). It also provides examples of prompts and techniques, such as question clustering and demonstration sampling, and discusses the importance of diversity and heuristics in generating reasoning chains. Additionally, it mentions the availability of code for Auto-CoT and provides a discount code for the DAIR.AI Academy.'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5be5d604-3d95-476a-afe4-b46b021534fc",
   "metadata": {
    "height": 167
   },
   "outputs": [],
   "source": [
    "class Paper(BaseModel):\n",
    "    \"\"\"Information about papers mentioned.\"\"\"\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2a8dcce7-7032-49a8-893d-1659e2f51f03",
   "metadata": {
    "height": 197
   },
   "outputs": [],
   "source": [
    "template = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article. \n",
    "\n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an EMPTY LIST.\n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\n",
    "\n",
    "if the input is irrelevant, return an empty list.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a5f4c8cc-d9a4-4556-a89e-94ec981c6f5e",
   "metadata": {
    "height": 44
   },
   "outputs": [],
   "source": [
    "extraction_functions = [convert_to_openai_function(Info)]\n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\":\"Info\"})\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b63e00b6-0f06-4e74-948e-04805e66f40c",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Chain-of-Thought Prompting', 'author': 'Wei et al. (2022)'},\n",
       " {'title': 'Zero-shot CoT Prompting', 'author': 'Kojima et al. (2022)'},\n",
       " {'title': 'Automatic Chain-of-Thought (Auto-CoT)',\n",
       "  'author': 'Zhang et al. (2022)'}]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "365bfa5b-f0d2-4a19-8db1-1b4a0f51703d",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1fe01",
   "metadata": {},
   "source": [
    "Split into pieces of texts and pass to the LLM and combine all the results of the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7a3e18b5-0692-49dc-b589-5d4ae5a43fdd",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a851b07c-0f73-4cf1-801f-9832190db93a",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "splits = text_splitter.split_text(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fbd6fd3c-8fca-4f16-a256-a66577b48eb1",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6f1309bf-16a5-43ef-aa8e-427cf5120938",
   "metadata": {
    "height": 99
   },
   "outputs": [],
   "source": [
    "# Function to flatten a 2D matrix into a 1D list\n",
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "67bded5d-de85-488c-bd3f-d83acbcfea33",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "04233d0a-fe44-45ed-9145-af3caaa86863",
   "metadata": {
    "height": 65
   },
   "outputs": [],
   "source": [
    "# This RunnableLambda prepares the input for extraction by splitting it into chunks\n",
    "# and creating a list of dictionaries, each containing a chunk as the \"input\" value\n",
    "prep = RunnableLambda(\n",
    "    lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fa8c2f1e-f3ac-4d9c-8ded-541778a32ef9",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'hi'}]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3f7d0255-4b58-42c9-a747-44768a866633",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "chain = prep | extraction_chain.map() | flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0dfa1f67-7246-4f4f-8967-4d7266df7b7a",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Chain-of-Thought Prompting', 'author': 'Wei et al. (2022)'},\n",
       " {'title': 'Zero-shot CoT Prompting', 'author': 'Kojima et al. (2022)'},\n",
       " {'title': 'Automatic Chain-of-Thought (Auto-CoT)',\n",
       "  'author': 'Zhang et al. (2022)'}]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5f869-67cc-4b66-8d14-7d19dd01b22a",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
